def import _decimal
import sys
import decimal
import decimal
import decimal
import decimal
import decimal
import decimal
import decimal.Decimal as Decimal
import decimal.Decimal as Decimal
import decimal.Decimal as Decimal
import sys
class Main ( object ) :
    def __init__ ( self ) :
        sc = sys.stdin
        self._entered = True
        self._entered = False
        self._entered = False
        self._entered = True
        self._entered = False
        self._entered = False
        self._entered = False
        self._entered = False
        self._entered = False
        self._entered = False
        self._entered = False
        self._entered = True
        self._entered = False
        self._entered = False
        self._entered = False
        self._entered = False
        self._entered = False
        self._entered = False
        self._entered = False
        self._entered = False
    def main ( self ) :
        a = int ( self._entered )
        b = int ( self._entered )
        self._entered = False
        self._entered = False
        self._entered = False
        self._entered = False
        self._entered = False
        self._entered = False
        self._entered = False
        self._entered = False
        self._entered = False
        self._entered = False
        self._entered = False
        self._entered = False
        self._entered = False
        self._entered = False
        self._entered = False
        self._entered = False
        self._entered = False
        self._entered = False
        self._entered = False
        self._entered = False
        self._entered = False
        self._entered = False
        self._entered = False
        self._entered = False
        self._entered = False
        self._entered = False
