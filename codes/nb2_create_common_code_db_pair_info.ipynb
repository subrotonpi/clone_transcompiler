{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set this to get small dataset\n",
    "#directory : everything goes to this directory: storage/dataset\n",
    "#manually rename the folder for large and dataset_small and dataset_large\n",
    "small=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"~/PycharmProjects/code-trans-aug/\")\n",
    "dr = '~/PycharmProjects/code-trans-aug/storage/'\n",
    "print('ANTLR features required for this part\\nsetting problem class in antlr features')\n",
    "import pandas as pd\n",
    "column_names = ['f_loc', 'variable', 'arguments', 'operators', 'expressions', 'loops','operands', 'exceptions', 'exception_clause', 'mccable_complex' ]\n",
    "or_java_feat = pd.read_csv(dr+'feat_original/java_features.csv', names=column_names)\n",
    "or_py_feat = pd.read_csv(dr+'feat_original/python_features.csv', names=column_names)\n",
    "tr_java_feat = pd.read_csv(dr+'feat_trans/java_features.csv', names=column_names)\n",
    "tr_py_feat = pd.read_csv(dr+'feat_trans/python_features.csv', names=column_names)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_code(df):\n",
    "    cp = 1\n",
    "    cj = 1\n",
    "    refined = []\n",
    "    for index, row in df.iterrows():\n",
    "        if row.language_extension =='py':\n",
    "            if(len(row.code.split('\\n'))>6):\n",
    "                cp+=1\n",
    "                refined.append(list(row))\n",
    "        if row.language_extension =='java':\n",
    "            if(len(row.code.split(';'))>6):\n",
    "                cj+=1\n",
    "                refined.append(list(row))\n",
    "    print(df[df.language_extension =='py'].shape[0]+ df[df.language_extension =='java'].shape[0], pd.DataFrame(refined).shape, (cp+cj)/df.shape[0])\n",
    "    return pd.DataFrame(refined, columns=list(df.columns))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_class_label(df, id_):\n",
    "    pc = []\n",
    "    fp = []\n",
    "    #uid =[]\n",
    "    for i in range(len(df)):\n",
    "        p = df.iloc[i]['f_loc'].split('/')[7:-1]\n",
    "        s = \"/\".join(p)\n",
    "        q = df.iloc[i]['f_loc'].split('/')[7:]\n",
    "        t = \"/\".join(q)\n",
    "        #uid.append(id_)\n",
    "        #id_= id_ + 1\n",
    "        fp.append(t)\n",
    "        pc.append(s)\n",
    "        \n",
    "        \n",
    "    df['file_path'] = fp\n",
    "    df['problem_class'] = pc\n",
    "    #df['id'] = uid\n",
    "    \n",
    "    return id_\n",
    "    \n",
    "id_ = set_class_label(or_java_feat, 1) #send each feature csv as argument\n",
    "id_ = set_class_label(or_py_feat, id_)\n",
    "id_ = set_class_label(tr_java_feat, id_)\n",
    "id_ = set_class_label(tr_py_feat, id_)  \n",
    "\n",
    "or_java_feat_pc = or_java_feat.iloc[: , 1:]\n",
    "or_py_feat_pc = or_py_feat.iloc[: , 1:]\n",
    "\n",
    "tr_java_feat_pc = tr_java_feat.iloc[: , 1:]\n",
    "tr_py_feat_pc =tr_py_feat.iloc[: , 1:]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(or_java_feat_pc.shape,or_py_feat_pc.shape, tr_java_feat.shape, tr_py_feat.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ofp = pd.read_pickle(dr+'data_original.pkl').sample(frac=.7) #all fragments original dataset\n",
    "ojava = ofp[ofp['language_extension']=='java']\n",
    "opy = ofp[ofp['language_extension']=='py']\n",
    "\n",
    "tfp = pd.read_pickle(dr+'data_transpiled.pkl')#all transpiled \n",
    "tjava = tfp[tfp['language_extension']=='java']\n",
    "tpy = tfp[tfp['language_extension']=='py']\n",
    "\n",
    "print(ofp.shape, tfp.shape, ofp.shape[0]-tfp.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ofp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_id(temp, from_df):\n",
    "    uid = []\n",
    "    for i in range(len(temp)):\n",
    "        f = temp.iloc[i]['file_path']\n",
    "        k = from_df[from_df['file_path']==f].iloc[0]['id']\n",
    "        uid.append(k)\n",
    "    temp['id'] = uid\n",
    "    return temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = or_java_feat_pc[or_java_feat_pc['file_path'].isin(ojava['file_path'])]\n",
    "temp = set_id(temp, ojava)\n",
    "temp.to_csv(dr+'feat_original/java_features_pc_id.csv', index=False, header=None)\n",
    "java_features_pc_id = temp\n",
    "temp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = or_py_feat_pc[or_py_feat_pc['file_path'].isin(opy['file_path'])]\n",
    "temp = set_id(temp, opy)\n",
    "temp.to_csv(dr+'feat_original/python_features_pc_id.csv', index=False, header=None)\n",
    "python_features_pc_id = temp\n",
    "temp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = tr_java_feat_pc[tr_java_feat_pc['file_path'].isin(tjava['file_path'])]\n",
    "temp = set_id(temp, tjava)\n",
    "temp.to_csv(dr+'feat_trans/java_features_pc_id.csv', index=False, header=None)\n",
    "trans_java_features_pc_id = temp\n",
    "temp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = tr_py_feat_pc[tr_py_feat_pc['file_path'].isin(tpy['file_path'])]\n",
    "temp = set_id(temp, tpy)\n",
    "temp.to_csv(dr+'feat_trans/python_features_pc_id.csv', index=False, header=None)\n",
    "trans_python_features_pc_id = temp\n",
    "temp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#augmented: merged dataset(or+tr)\n",
    "\n",
    "ojava = pd.read_csv(dr+'feat_original/java_features_pc_id.csv', header=None)\n",
    "opy = pd.read_csv(dr+'feat_original/python_features_pc_id.csv', header=None)\n",
    "\n",
    "tjava = pd.read_csv(dr+'feat_trans/java_features_pc_id.csv', header=None)\n",
    "tpy = pd.read_csv(dr+'feat_trans/python_features_pc_id.csv', header=None)\n",
    "\n",
    "ojava.append(tjava).to_csv(dr+'feat_aug/pair_creation_augmented_java.csv', header=None, index=False)\n",
    "opy.append(tpy).to_csv(dr+'feat_aug/pair_creation_augmented_py.csv', header=None, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "originals_ids_clc = list(python_features_pc_id.id) + list(java_features_pc_id.id)\n",
    "trans_ids_clc = list(trans_python_features_pc_id.id) + list(trans_java_features_pc_id.id)\n",
    "len(originals_ids_clc), len(trans_ids_clc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "12 in originals_ids_clc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "dr = '~/PycharmProjects/code-trans-aug/storage/'\n",
    "\n",
    "original = pd.read_pickle(dr+'data_original.pkl')\n",
    "print(original.shape)\n",
    "trans = pd.read_pickle(dr+'data_transpiled.pkl')\n",
    "print(trans.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# filter to get small dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if small==True:\n",
    "    original = filter_code(original)\n",
    "    trans = filter_code(trans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "original = original[original.id.isin(originals_ids_clc)]\n",
    "trans = trans[trans.id.isin(trans_ids_clc)]\n",
    "\n",
    "print(original.shape)\n",
    "print(trans.shape)\n",
    "print(original.is_translated.unique(), trans.is_translated.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#original GMN pairs : java and python\n",
    "# input: java and java prime [original python to java prime] [parsable and all]\n",
    "\n",
    "#augmented GMN pairs: java+python_to_java_prime and python+java_to_python_prime\n",
    "#input : java+java' and convert to java(python and pythone prime both (this case python is double converted))\n",
    "# merged dataset(or+tr)\n",
    "\n",
    "#python : python and python prime[original java to python prime]\n",
    "#AUG : original java ; original python cnv java(same as java prime) + python prime cnv java, java prime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "java_original = original[original.language_extension=='java']\n",
    "print(java_original.shape)\n",
    "trans = trans.sort_values(['id'])\n",
    "#python original converted for gmn input\n",
    "python_original_cnv_jv = trans[trans.language_extension=='java']\n",
    "print(python_original_cnv_jv.shape)\n",
    "python_original_cnv_jv['id'] = [k-38110 for k in list(python_original_cnv_jv.id)]\n",
    "python_original_cnv_jv.language_extension = 'py'\n",
    "print(python_original_cnv_jv.shape)\n",
    "\n",
    "gmn_original = pd.concat([java_original, python_original_cnv_jv])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gmn_original.shape, original.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gmn_original = gmn_original[gmn_original.id.isin(original.id)]\n",
    "print(gmn_original.shape)\n",
    "original = original[original.id.isin(gmn_original.id)]\n",
    "print(original.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "12 in original.id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "python_to_java_prime = trans[trans.language_extension=='java']\n",
    "print(python_to_java_prime.shape)\n",
    "#trans[trans.language_extension=='py'].sort_values(['file_path'])\n",
    "#java_to_python_prime is converted as following\n",
    "python_prime_to_java = pd.read_pickle('~/PycharmProjects/code-trans-aug/storage/python_prime_to_java.pkl')\n",
    "python_prime_to_java.sort_values(['file_path'])\n",
    "python_prime_to_java = python_prime_to_java[python_prime_to_java.id.isin(trans.id)]\n",
    "print(\n",
    "    list(python_prime_to_java.sort_values(['file_path']).file_path) == \n",
    "    list(trans[trans.language_extension=='py'].sort_values(['file_path']).file_path)\n",
    ")\n",
    "print(python_prime_to_java.shape)\n",
    "python_prime_to_java = python_prime_to_java[python_prime_to_java.language_extension!='error']\n",
    "print(python_prime_to_java.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gmn_transpiled = pd.concat([python_prime_to_java, python_to_java_prime])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gmn_transpiled.shape, trans.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trans = trans[trans.id.isin(gmn_transpiled.id)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gmn_transpiled.shape, trans.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gmn_transpiled = gmn_transpiled[gmn_transpiled.id.isin(trans.id)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "java_original.shape, python_original_cnv_jv.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "python_prime_to_java.shape, python_to_java_prime.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gmn_original.shape, original.shape, gmn_transpiled.shape, trans.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "original.sort_values(['id'], inplace=True)\n",
    "gmn_original.sort_values(['id'], inplace=True)\n",
    "\n",
    "trans.sort_values(['id'], inplace=True)\n",
    "gmn_transpiled.sort_values(['id'], inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(gmn_original.id) == list(original.id),list(gmn_original.problem_class) == list(original.problem_class)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(gmn_transpiled.id) == list(trans.id), list(gmn_transpiled.problem_class) == list(trans.problem_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#original.to_pickle('original_data_final.pkl')\n",
    "codes = pd.concat([original, trans])\n",
    "gmn_codes = pd.concat([gmn_original, gmn_transpiled])\n",
    "mapping = {item:i+1 for i, item in enumerate(codes[\"problem_class\"].unique())}\n",
    "codes[\"task\"] = codes['problem_class'].apply(lambda x: mapping[x])\n",
    "gmn_codes[\"task\"] = gmn_codes['problem_class'].apply(lambda x: mapping[x])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(gmn_codes.task) == list(codes.task)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "codes.to_pickle(dr+'dataset/codes.pkl')\n",
    "codes.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(set(gmn_codes.id)) == gmn_codes.shape[0])\n",
    "gmn_codes_dict = dict(gmn_codes[['id', 'code']].values)\n",
    "df = pd.DataFrame(gmn_codes_dict.items())\n",
    "df.to_pickle(dr+'dataset/gmn_codes_dict.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_map(df):\n",
    "    df[\"task\"] = df['problem_class'].apply(lambda x: mapping[x])\n",
    "    return df\n",
    "\n",
    "original = get_map(original)\n",
    "original.to_pickle(dr+'dataset/original_final.pkl')\n",
    "trans = get_map(trans)\n",
    "trans.to_pickle('dataset/transpiled_final.pkl')\n",
    "\n",
    "gmn_original = get_map(gmn_original)\n",
    "gmn_original.to_pickle(dr+'dataset/gmn_original_final.pkl')\n",
    "gmn_transpiled = get_map(gmn_transpiled)\n",
    "gmn_transpiled.to_pickle('dataset/gmn_transpiled_final.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(gmn_original.language_extension) == list(original.language_extension)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(trans.language_extension) == list(gmn_transpiled.language_extension)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def  filter_for_pair (df):\n",
    "    df = df[['id', 'task']]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_java = original[original.language_extension=='java']\n",
    "original_java = filter_for_pair(original_java)\n",
    "original_java.to_csv('dataset/java_original.csv', header=None, index=False)\n",
    "\n",
    "original_python = original[original.language_extension=='py']\n",
    "original_python = filter_for_pair(original_python)\n",
    "original_python.to_csv('dataset/python_original.csv', header=None, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trans_java = trans[trans.language_extension=='java']\n",
    "pd.concat([filter_for_pair(trans_java), original_java]).to_csv('dataset/java_aug.csv', header=None, index=False)\n",
    "\n",
    "trans_python = trans[trans.language_extension=='py']\n",
    "pd.concat([filter_for_pair(trans_python), original_python]).to_csv('dataset/python_aug.csv', header=None, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run Code inside Java Runner to get the pairs first."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- now read clones and non clones\n",
    "- merge pairs\n",
    "- sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "dr = '~/PycharmProjects/code-trans-aug/storage/'\n",
    "clones =pd.read_csv(dr+'dataset/clones.csv', header=None)\n",
    "print(clones.shape)\n",
    "\n",
    "non_clones =pd.read_csv(dr+'dataset/non_clones.csv', header=None).sample(clones.shape[0])\n",
    "print(non_clones.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ag_clones =pd.read_csv(dr+'dataset/clones_augmented.csv', header=None)\n",
    "print(ag_clones.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ag_non_clones =pd.read_csv(dr+'dataset/non_clones_augmented.csv', header=None).sample(ag_clones.shape[0])\n",
    "print(ag_non_clones.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if small==True:\n",
    "    do = pd.concat([clones, non_clones]).sample(frac=.6)\n",
    "    do.to_csv(dr+'dataset/dataset_org.csv', header=None, index=False)\n",
    "\n",
    "    da = pd.concat([ag_clones, ag_non_clones])\n",
    "    da.to_csv(dr+'dataset/dataset_aug.csv', index=False)\n",
    "\n",
    "    dataset_or_80_20_aug = pd.concat([do, da.sample(int(len(do)*0.25))])\n",
    "    dataset_or_80_20_aug = dataset_or_80_20_aug.to_csv(dr+'dataset/dataset_or_80_20_aug.csv', header=None, index=False)\n",
    "else:\n",
    "    do = pd.concat([clones, non_clones])\n",
    "    do.to_csv(dr+'dataset/dataset_org.csv', header=None, index=False)\n",
    "\n",
    "    da = pd.concat([ag_clones, ag_non_clones])\n",
    "    da.to_csv(dr+'dataset/dataset_aug.csv', index=False)\n",
    "\n",
    "    dataset_or_80_20_aug = pd.concat([do, da.sample(int(len(do)*0.25))])\n",
    "    dataset_or_80_20_aug = dataset_or_80_20_aug.to_csv(dr+'dataset/dataset_or_80_20_aug.csv', header=None, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.9 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9 (default, Apr 13 2022, 08:48:07) \n[Clang 13.1.6 (clang-1316.0.21.2.5)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
